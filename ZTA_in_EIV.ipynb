{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import optimizers\n",
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Load and Combine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load attack and ambient datasets\n",
    "can_data = pd.read_csv(r\"G:\\road\\signal_extractions\\attacks\\correlated_signal_attack_1_masquerade.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocess Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "can_data.fillna(0, inplace=True)  # Replace NaNs with 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Normalize Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamps to uniform intervals (e.g., 10 Hz)\n",
    "signal_columns = [col for col in can_data.columns if \"Signal\" in col]  # Identify all signal columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    7.415100e+04\n",
      "mean     4.464114e-04\n",
      "std      6.610735e-04\n",
      "min      1.192093e-07\n",
      "25%      9.536743e-07\n",
      "50%      1.907349e-06\n",
      "75%      1.006067e-03\n",
      "max      4.119039e-03\n",
      "Name: Time, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check the time differences between each row for sampling rate\n",
    "time_diffs = can_data['Time'].diff().dropna()\n",
    "print(time_diffs.describe()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'Time' column is in datetime format\n",
    "can_data['Time'] = pd.to_datetime(can_data['Time'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data by time\n",
    "can_data = can_data.sort_values('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 'Time' as the index\n",
    "can_data.set_index('Time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure signal columns are numeric\n",
    "can_data[signal_columns] = can_data[signal_columns].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample at 100Âµs (0.1ms) to retain more details\n",
    "can_data = can_data.resample('100us').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate missing values using cubic interpolation for smoother transitions\n",
    "can_data = can_data.interpolate(method='cubic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index after resampling\n",
    "can_data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Time  Label           ID  Signal_1_of_ID  \\\n",
      "0      1970-01-01 00:00:00.000000    0.0   852.000000    32808.000000   \n",
      "1      1970-01-01 00:00:00.000100    0.0   897.633224    26911.493851   \n",
      "2      1970-01-01 00:00:00.000200    0.0   923.437535    21708.051223   \n",
      "3      1970-01-01 00:00:00.000300    0.0   931.218924    17156.830057   \n",
      "4      1970-01-01 00:00:00.000400    0.0   922.783381    13216.988297   \n",
      "...                           ...    ...          ...             ...   \n",
      "331014 1970-01-01 00:00:33.101400    0.0  1082.926392     2682.440185   \n",
      "331015 1970-01-01 00:00:33.101500    0.0   865.442574     2214.631360   \n",
      "331016 1970-01-01 00:00:33.101600    0.0   615.794156     1629.515787   \n",
      "331017 1970-01-01 00:00:33.101700    0.0   332.480258      920.002366   \n",
      "331018 1970-01-01 00:00:33.101800    0.0    14.000000       79.000000   \n",
      "\n",
      "        Signal_2_of_ID  Signal_3_of_ID  Signal_4_of_ID  Signal_5_of_ID  \\\n",
      "0             0.000000       78.000000        9.000000        0.000000   \n",
      "1            50.963968       14.688920       21.006928       37.694916   \n",
      "2            92.222999      -31.390766       28.903774       68.487227   \n",
      "3           124.488197      -62.068658       33.158324       92.870001   \n",
      "4           148.470666      -79.174355       34.238365      111.336303   \n",
      "...                ...             ...             ...             ...   \n",
      "331014       98.515012     8604.422815       19.777118     -111.659786   \n",
      "331015       80.938691     9958.010033       16.213451      -91.165873   \n",
      "331016       59.001693    11437.179272       11.764949      -65.896133   \n",
      "331017       32.442602    13046.864579        6.378252      -35.593272   \n",
      "331018        1.000000    14792.000000        0.000000        0.000000   \n",
      "\n",
      "        Signal_6_of_ID  Signal_7_of_ID  ...  Signal_13_of_ID  Signal_14_of_ID  \\\n",
      "0             0.000000        0.000000  ...         0.000000     0.000000e+00   \n",
      "1          2548.051677       34.879512  ...        -0.000024    -2.656206e-08   \n",
      "2          4624.808088       64.371283  ...        -0.000040    -4.473610e-08   \n",
      "3          6264.129817       88.816174  ...        -0.000049    -5.545412e-08   \n",
      "4          7499.877451      108.555044  ...        -0.000053    -5.964813e-08   \n",
      "...                ...             ...  ...              ...              ...   \n",
      "331014     2699.730248     -121.874108  ...        -0.000015   -8.264468e-139   \n",
      "331015     2212.814614      -99.421949  ...        -0.000012   -6.773912e-139   \n",
      "331016     1605.375308      -71.806212  ...        -0.000009   -4.914407e-139   \n",
      "331017      870.180910      -38.755897  ...        -0.000005   -2.663815e-139   \n",
      "331018        0.000000        0.000000  ...         0.000000     0.000000e+00   \n",
      "\n",
      "        Signal_15_of_ID  Signal_16_of_ID  Signal_17_of_ID  Signal_18_of_ID  \\\n",
      "0              0.000000         0.000000     0.000000e+00     0.000000e+00   \n",
      "1             -0.000004        -0.000390    7.266509e-162    3.633255e-162   \n",
      "2             -0.000007        -0.000658    1.223833e-161    6.119166e-162   \n",
      "3             -0.000009        -0.000815    1.517043e-161    7.585216e-162   \n",
      "4             -0.000010        -0.000877    1.631777e-161    8.158887e-162   \n",
      "...                 ...              ...              ...              ...   \n",
      "331014        -0.000023        -0.002315   -4.132234e-139   -2.066117e-139   \n",
      "331015        -0.000019        -0.001898   -3.386956e-139   -1.693478e-139   \n",
      "331016        -0.000014        -0.001377   -2.457204e-139   -1.228602e-139   \n",
      "331017        -0.000007        -0.000746   -1.331908e-139   -6.659538e-140   \n",
      "331018         0.000000         0.000000     0.000000e+00     0.000000e+00   \n",
      "\n",
      "        Signal_19_of_ID  Signal_20_of_ID  Signal_21_of_ID  Signal_22_of_ID  \n",
      "0          0.000000e+00     0.000000e+00              0.0              0.0  \n",
      "1         6.176533e-161    3.633255e-162              0.0              0.0  \n",
      "2         1.040258e-160    6.119166e-162              0.0              0.0  \n",
      "3         1.289487e-160    7.585216e-162              0.0              0.0  \n",
      "4         1.387011e-160    8.158887e-162              0.0              0.0  \n",
      "...                 ...              ...              ...              ...  \n",
      "331014   -3.512399e-138   -2.066117e-139              0.0              0.0  \n",
      "331015   -2.878913e-138   -1.693478e-139              0.0              0.0  \n",
      "331016   -2.088623e-138   -1.228602e-139              0.0              0.0  \n",
      "331017   -1.132121e-138   -6.659538e-140              0.0              0.0  \n",
      "331018     0.000000e+00     0.000000e+00              0.0              0.0  \n",
      "\n",
      "[331019 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "print(can_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Create Sliding Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_series(data, window_size, step_size):\n",
    "    \"\"\"\n",
    "    Generate time-series data using a sliding window approach.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: Pandas DataFrame containing the resampled data.\n",
    "    - window_size: Number of samples in each window (e.g., 100,000 for 10 seconds at 10,000 Hz).\n",
    "    - step_size: Step size in samples (e.g., 10,000 for 1 second at 10,000 Hz).\n",
    "    \n",
    "    Returns:\n",
    "    - sequences: Numpy array of signal data sequences.\n",
    "    - labels: Numpy array of labels for each sequence.\n",
    "    \"\"\"\n",
    "    sequences, labels = [], []\n",
    "    for i in range(0, len(data) - window_size, step_size):\n",
    "        # Extract window\n",
    "        window = data.iloc[i:i + window_size]\n",
    "        \n",
    "        # Extract signal data for the window\n",
    "        sequences.append(window[signal_columns].values)\n",
    "        \n",
    "        label = 1 if (window['Label'].sum() > (window_size / 2)) else 0 # Majority vote\n",
    "        #label = 1 if (window['Label'].sum() > 0) else 0 # Any attack label and the window is labeled as an attack for less computational ressources\n",
    "        labels.append(label)\n",
    "    \n",
    "    return np.array(sequences), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Adjusted parameters for higher frequency data (100Âµs, 10,000 Hz)\n",
    "sampling_rate = 10000  # Hz (I changed this to 1000 Hz for less computation time during code testing)\n",
    "window_size = 10 #(0.5 * sampling_rate)  # 10 seconds = 100,000 samples\n",
    "step_size = 1 #(0.1 * sampling_rate)  # 1 second = 10,000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate time-series data\n",
    "X, y = create_time_series(can_data, window_size, step_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Split Data into Train/Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN or inf values with 0\n",
    "X_train = np.nan_to_num(X_train)\n",
    "X_test = np.nan_to_num(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform training data\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "X_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adressing data imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" ideas...\\n\\n# Combine features and labels into a single DataFrame\\ntrain_data = pd.DataFrame(X_train.reshape(X_train.shape[0], -1))\\ntrain_data[\\'label\\'] = y_train\\n\\n# Separate majority and minority classes\\nmajority = train_data[train_data[\\'label\\'] == 0]\\nminority = train_data[train_data[\\'label\\'] == 1]\\n\\n# Oversample the minority class\\nminority_oversampled = resample(minority, replace=True, n_samples=len(majority), random_state=42)\\n\\n# Combine back the oversampled dataset\\nbalanced_train_data = pd.concat([majority, minority_oversampled])\\nX_train = balanced_train_data.drop(\\'label\\', axis=1).values.reshape(-1, X_train.shape[1], X_train.shape[2])\\ny_train = balanced_train_data[\\'label\\'].values\\n'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\" ideas...\n",
    "\n",
    "# Combine features and labels into a single DataFrame\n",
    "train_data = pd.DataFrame(X_train.reshape(X_train.shape[0], -1))\n",
    "train_data['label'] = y_train\n",
    "\n",
    "# Separate majority and minority classes\n",
    "majority = train_data[train_data['label'] == 0]\n",
    "minority = train_data[train_data['label'] == 1]\n",
    "\n",
    "# Oversample the minority class\n",
    "minority_oversampled = resample(minority, replace=True, n_samples=len(majority), random_state=42)\n",
    "\n",
    "# Combine back the oversampled dataset\n",
    "balanced_train_data = pd.concat([majority, minority_oversampled])\n",
    "X_train = balanced_train_data.drop('label', axis=1).values.reshape(-1, X_train.shape[1], X_train.shape[2])\n",
    "y_train = balanced_train_data['label'].values\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build LSTM Model (old approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel = Sequential([\\n    LSTM(64, activation=\\'relu\\', input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True),\\n    Dropout(0.3),\\n    LSTM(32, activation=\\'relu\\'),\\n    Dense(1, activation=\\'sigmoid\\')  # Output: Trust score (0 or 1 for binary classification)\\n])\"\\n'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    LSTM(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Output: Trust score (0 or 1 for binary classification)\n",
    "])\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build CNN + LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # CNN Feature Extraction\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    MaxPooling1D(pool_size=2),  # Downsample to reduce dimensionality\n",
    "    Dropout(0.3),  # Prevent overfitting\n",
    "\n",
    "    # LSTM for Sequential Analysis\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    LSTM(32),\n",
    "    \n",
    "    # Fully Connected Layer\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification (0 = normal, 1 = attack)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001, clipnorm=1.0) # add clipvalue=0.5 to avoid exploding gradients\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy','Precision','Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4138/4138 [==============================] - 63s 14ms/step - loss: 0.0827 - accuracy: 0.9787 - precision: 0.8095 - recall: 0.4503 - val_loss: 0.0167 - val_accuracy: 0.9947 - val_precision: 0.8964 - val_recall: 0.9413\n",
      "Epoch 2/5\n",
      "4138/4138 [==============================] - 52s 13ms/step - loss: 0.0337 - accuracy: 0.9879 - precision: 0.8330 - recall: 0.7870 - val_loss: 0.0169 - val_accuracy: 0.9942 - val_precision: 0.8634 - val_recall: 0.9718\n",
      "Epoch 3/5\n",
      "4138/4138 [==============================] - 56s 14ms/step - loss: 0.0311 - accuracy: 0.9889 - precision: 0.8493 - recall: 0.8006 - val_loss: 0.0415 - val_accuracy: 0.9808 - val_precision: 0.6255 - val_recall: 0.9780\n",
      "Epoch 4/5\n",
      "4138/4138 [==============================] - 58s 14ms/step - loss: 0.0288 - accuracy: 0.9897 - precision: 0.8589 - recall: 0.8182 - val_loss: 0.0152 - val_accuracy: 0.9951 - val_precision: 0.9004 - val_recall: 0.9494\n",
      "Epoch 5/5\n",
      "4138/4138 [==============================] - 59s 14ms/step - loss: 0.0271 - accuracy: 0.9903 - precision: 0.8617 - recall: 0.8368 - val_loss: 0.0157 - val_accuracy: 0.9939 - val_precision: 0.8684 - val_recall: 0.9508\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntest_loss, test_acc = model.evaluate(X_test)\\nprint(f\"Test Accuracy: {test_acc}\")\\npreds = model.predict(X_test[:10])\\nprint(preds)\"\\n'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "\"\"\"\n",
    "test_loss, test_acc = model.evaluate(X_test)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "preds = model.predict(X_test[:10])\n",
    "print(preds)\"\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([256192,   8615], dtype=int64))\n",
      "(array([0, 1]), array([64107,  2095], dtype=int64))\n",
      "(264807, 10, 22)\n",
      "(66202, 10, 22)\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train, return_counts=True)) # Check class distribution and balance\n",
    "print(np.unique(y_test, return_counts=True)) # Check class distribution and balance\n",
    "print(X_train.shape)  # Should be (num_samples, timesteps, num_features)\n",
    "print(X_test.shape)   # Should match training dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Labels Distribution: (array([0, 1]), array([256192,   8615], dtype=int64))\n",
      "Validation Labels Distribution: (array([0, 1]), array([64107,  2095], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Labels Distribution:\", np.unique(y_train, return_counts=True))\n",
    "print(\"Validation Labels Distribution:\", np.unique(y_test, return_counts=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v2x_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
